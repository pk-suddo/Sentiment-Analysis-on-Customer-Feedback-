{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4016446",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44952124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61e79b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "dataset = pd.read_csv('Restaurant_Reviews 2.csv')\n",
    "dataset.head()  # Display the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d1818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cccf698",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7ed53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pritamthakulakshetri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Initialize corpus to store processed reviews\n",
    "corpus = []\n",
    "\n",
    "# Loop through each review in the dataset\n",
    "for i in range(0, len(dataset)):\n",
    "    # Clean the text\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    all_stopwords.remove('no')\n",
    "    all_stopwords.remove('but')\n",
    "    all_stopwords.remove(\"won't\")\n",
    "    review = [ps.stem(word) for word in review if word not in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc8d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42a382d3",
   "metadata": {},
   "source": [
    "# Feature extraction using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab82c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset['Liked'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74c115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265ff59",
   "metadata": {},
   "source": [
    "# Model selection and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840cacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(C=1.)),\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('Support Vector Machine', SVC(C=1., kernel='rbf')),\n",
    "    ('Random Forest', RandomForestClassifier())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c82997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.78\n",
      "Naive Bayes accuracy: 0.8\n",
      "Support Vector Machine accuracy: 0.775\n",
      "Random Forest accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925e9cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression\n",
      "Accuracy with k-fold cross-validation: 0.80375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model selection using cross-validation\n",
    "best_model = models[0][1]\n",
    "best_accuracy = 0\n",
    "\n",
    "for model_name, model in models:\n",
    "    accuracy_scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_model = model_name\n",
    "\n",
    "print(f'Best model: {best_model}')\n",
    "print(f'Accuracy with k-fold cross-validation: {best_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe08e5",
   "metadata": {},
   "source": [
    "\n",
    "# Save the best model and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c8fa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative sentiment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(classifier, 'logistic_regression_NLPreviews.joblib')\n",
    "joblib.dump(cv, 'vectorizer_reviews.joblib')\n",
    "\n",
    "# Load the saved model and vectorizer\n",
    "loaded_model = joblib.load('logistic_regression_NLPreviews.joblib')\n",
    "loaded_vectorizer = joblib.load('vectorizer_reviews.joblib')\n",
    "\n",
    "# Make predictions on new reviews\n",
    "new_review = loaded_vectorizer.transform(['I like the food'])\n",
    "predictions = loaded_model.predict(new_review)\n",
    "\n",
    "# Display sentiment based on predictions\n",
    "if predictions[0] == 0:\n",
    "    print('negative sentiment')\n",
    "else:\n",
    "    print('positive sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f869c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
